{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import eikon as ek\n",
    "import sys\n",
    "#import config\n",
    "#ek.set_app_key(config.eikon_key)\n",
    "import cufflinks as cf\n",
    "import configparser as cp\n",
    "cf.set_config_file(offline = True)\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "#import DatastreamDSWS as DSWS\n",
    "#ds = DSWS.Datastream(username = 'JGarden1@lidoadvisors.com', password= 'Welcome2')\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import chart_studio\n",
    "from chart_studio.plotly import plot, iplot\n",
    "import chart_studio.plotly as py\n",
    "from PIL import Image as im\n",
    "#import Lido_funcs3 as lf\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import validation_curve\n",
    "import IPython.display\n",
    "from IPython.display import Image\n",
    "chart_studio.tools.set_credentials_file(username='JGarden79', api_key='eWGoAmjzRp3GIVRTFfSR')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import chart_studio.tools as tls\n",
    "\n",
    "import plotly.io as pio\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_SECT_1():\n",
    "    '''Calls Data from Datastream web services and stores in a csv. This will not run without a Thomson Reuters \n",
    "    Terminal running as well as a subscription to both TR and DS'''\n",
    "    raw = ds.get_data(tickers='USSPRPER, TRUS10T, TRUS3MT, USCPCOREE, USUN%TOTQ, USCNFBUSQ, USNBERBCR, USPERCONB, USUMCONSH', start='BDATE', fields='X', freq='M').dropna()\n",
    "    raw = raw.droplevel(level = 1, axis = 1)\n",
    "    raw.columns=raw.columns.rename('')\n",
    "    clean = raw.rename(columns = {\"USSPRPER\": 'Valuation', ' TRUS10T': 'ten_yr', ' TRUS3MT': 'three_mth', ' USCPCOREE': 'Core_INF',\n",
    "                                  ' USUN%TOTQ':'Unemployment',\n",
    "                                  ' USCNFBUSQ': 'PMI', ' USPERCONB': 'Personal Consump', ' USUMCONSH': 'UMICH Sent', ' USNBERBCR': 'Recession',})\n",
    "    clean.to_csv('Section_1_DATA.csv')\n",
    "    \n",
    "    funds = ds.get_data(tickers='519793, 519822', start='BDATE', fields=['RI'], freq='M').dropna()\n",
    "    funds = funds.droplevel(level = 1, axis = 1)\n",
    "    funds.columns = funds.columns.rename('')\n",
    "    funds = funds.rename(columns = {'519793': 'Vanguard Total Bond', ' 519822': 'Vanguard 500 Stock'})\n",
    "    funds.to_csv('Sect_1_Funds.csv')\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_data_SECT_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing_1(df):\n",
    "    df = pd.read_csv(df)\n",
    "    twlv = df['Recession'].shift(-12).replace(np.nan, 0.0)\n",
    "    twlv = twlv.rename('12_to_rec')\n",
    "    clean = df.join(twlv)\n",
    "    clean = clean.dropna()\n",
    "    clean['Dates'] = pd.to_datetime(clean['Dates'])\n",
    "    clean = clean.set_index('Dates')\n",
    "    clean['inf_adj'] = clean['Core_INF'].pct_change(12)\n",
    "    clean['Slope'] = (clean['ten_yr'] - clean['three_mth'])\n",
    "    clean = clean.drop(['ten_yr', 'three_mth'], axis = 1)\n",
    "    clean['Valuation'] = (clean['Valuation'] - clean['Valuation'].expanding(36).mean())/clean['Valuation'].expanding(36).std()\n",
    "    clean['inf_adj'] = (clean['inf_adj'] - clean['inf_adj'].rolling(36).mean())/clean['inf_adj'].rolling(36).std()\n",
    "    clean = clean.drop('Core_INF', axis = 1)\n",
    "    clean['Employment'] = 100 - clean['Unemployment']\n",
    "    clean['Employment'] = (clean['Employment'] - clean['Employment'].expanding(36).mean())/clean['Employment'].expanding(36).std()\n",
    "    clean = clean.drop('Unemployment', axis = 1)\n",
    "    clean['PMI'] = (clean['PMI'] - clean['PMI'].expanding(36).mean())/clean['PMI'].expanding(36).std()\n",
    "    clean['Personal Consump'] = clean['Personal Consump'].pct_change(12)\n",
    "    clean['Personal Consump'] = (clean['Personal Consump'] - clean['Personal Consump'].expanding(36).mean())/clean['Personal Consump'].expanding(36).std()\n",
    "    clean['UMICH Sent'] = (clean['UMICH Sent'] - clean['UMICH Sent'].expanding(36).mean())/clean['UMICH Sent'].expanding(36).std()\n",
    "    clean['Slope'] = (clean['Slope'] - clean['Slope'].expanding(36).mean())/clean['Slope'].expanding(36).std()\n",
    "    return clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_processing_1('Section_1_DATA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_prep_1(df):\n",
    "    df = df\n",
    "    X = df.drop(['Recession', '12_to_rec'], axis = 1)\n",
    "    y = df['12_to_rec']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42, test_size = 1/2)\n",
    "    \n",
    "    return X, y, X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, X_train, X_test, y_train, y_test = feature_prep_1(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_selection(X, y, X_train, X_test, y_train, y_test):\n",
    "    param_range = [0.01, 0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n",
    "\n",
    "    \n",
    "    clf = SVC(random_state = 42, probability = True)\n",
    "    param_grid = dict(C=param_range)\n",
    "    kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    grid_search = GridSearchCV(clf, param_grid, scoring=\"neg_log_loss\", n_jobs=-1, cv=kfold)\n",
    "    grid_result = grid_search.fit(X,y)\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    for mean, stdev, param in zip(means, stds, params):\n",
    "        print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "    \n",
    "    C = grid_result.best_params_\n",
    "    C = C['C']\n",
    "    clf= SVC(random_state = 42,C = C).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred, target_names=['not 1', '1']))\n",
    "    y_score_clf = clf.fit(X_train, y_train).decision_function(X_test)\n",
    "    fpr_clf, tpr_clf, _ = roc_curve(y_test, y_score_clf)\n",
    "    roc_auc_clf = auc(fpr_clf, tpr_clf)\n",
    "    \n",
    "    \n",
    "    fig = px.area(\n",
    "        x=fpr_clf, y=tpr_clf,\n",
    "        title=f'Precision-Recall Curve<br>Logisitic Reg(AUC={auc(fpr_clf, tpr_clf):.4f})',\n",
    "        labels=dict(x='Recall', y='Precision'),\n",
    "        width=250, height=250\n",
    "    )\n",
    "    fig.add_shape(\n",
    "        type='line', line=dict(dash='dash'),\n",
    "        x0=0, x1=1, y0=0, y1=1\n",
    "    )\n",
    "    fig.update_yaxes( automargin=True)\n",
    "    fig.update_xaxes(constrain='domain')\n",
    "    fig.update_layout(font=dict(\n",
    "            size=9,\n",
    "            color=\"Black\"), margin=dict(\n",
    "            l=1,\n",
    "            r=1,\n",
    "            b=1,\n",
    "            t=50,\n",
    "            pad=0,\n",
    "        ))\n",
    "    \n",
    "    fig.show()\n",
    "    pio.write_html(fig, file='ROC_SVM.html', auto_open=True)\n",
    "    return C\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C= model_selection(X, y, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_1(X_train, X_test, y_train, y_test, C):\n",
    "    '''Trains model using different learning rates and estimators, selects model with best f1 score.'''\n",
    "    \n",
    "        \n",
    "    clf =  SVC(random_state = 42, C = C, probability = True).fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    f_1_fin = f1_score(y_test, y_pred, average = 'micro')\n",
    "    print(C, f_1_fin)\n",
    " \n",
    "    return clf\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = model_1( X_train, X_test, y_train, y_test, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perfomance_bt(funds, clf, X, indc):\n",
    "    funds = pd.read_csv(funds)\n",
    "    indicator = clf.predict_proba(X)[:,1]\n",
    "    df_vis = df\n",
    "    df_vis['indicator'] = indicator\n",
    "    funds = funds.set_index('Dates')\n",
    "    funds  = funds.join(df_vis['indicator'])\n",
    "    funds = funds.join(df_vis['Recession'])\n",
    "    funds['indicator'] = funds['indicator'].ewm(span = 4).mean()\n",
    "    funds = funds.replace(np.nan, 0)\n",
    "    stock = funds['Vanguard 500 Stock'].to_list()\n",
    "    bonds = funds['Vanguard Total Bond'].to_list()\n",
    "    indicator = funds['indicator'].to_list()\n",
    "    values = []\n",
    "    b_vals = []\n",
    "    e_vals = []\n",
    "    stock_shares = 60000/stock[0]\n",
    "    bond_shares = 40000/bonds[0]\n",
    "    stock_val = stock_shares * stock[0]\n",
    "    bond_val = bond_shares * bonds[0]\n",
    "    port_val = 100000\n",
    "    for i in range(0, len(indicator)):\n",
    "    ####Set Share Counts\n",
    "        if i < 6:\n",
    "            stock_val = stock_shares * stock[i]\n",
    "            bond_val = bond_shares * bonds[i]\n",
    "            port_val = stock_val+bond_val\n",
    "            values.append(port_val)\n",
    "        else:\n",
    "            if indicator[i] < 0.45 and indicator[i-1] < 0.45 and indicator[i-2] < 0.45 and indicator[i-3] < 0.45 and indicator[i-4] < 0.45 and indicator[i-5] < 0.45:\n",
    "                if stock_val > bond_val:\n",
    "                    stock_val = stock_shares * stock[i]\n",
    "                    bond_val = bond_shares * bonds[i]\n",
    "                    port_val = stock_val+bond_val\n",
    "                    values.append(port_val)\n",
    "                else:\n",
    "                    stock_val = 0.6 * port_val\n",
    "                    bond_val = 0.4 * port_val\n",
    "                    stock_shares = stock_val/stock[i]\n",
    "                    bond_shares = bond_val/bonds[i]\n",
    "                    stock_val = stock_shares * stock[i]\n",
    "                    bond_val = bond_shares * bonds[i]\n",
    "                    port_val = stock_val+bond_val\n",
    "                    values.append(port_val)\n",
    "            else:\n",
    "                if stock_val < bond_val:\n",
    "                    stock_val = stock_shares * stock[i]\n",
    "                    bond_val = bond_shares * bonds[i]\n",
    "                    port_val = stock_val+bond_val\n",
    "                    values.append(port_val)\n",
    "                else:\n",
    "                    stock_val = 0.4 * port_val\n",
    "                    bond_val = 0.6 * port_val\n",
    "                    stock_shares = stock_val/stock[i]\n",
    "                    bond_shares = bond_val/bonds[i]\n",
    "                    stock_val = stock_shares * stock[i]\n",
    "                    bond_val = bond_shares * bonds[i]\n",
    "                    port_val = stock_val+bond_val\n",
    "                    values.append(port_val)                \n",
    "        e_vals.append(stock_val)\n",
    "        b_vals.append(bond_val)\n",
    "    \n",
    "    \n",
    "    stock_shares = 60000/stock[0]\n",
    "    bond_shares = 40000/bonds[0]    \n",
    "    funds['Active'] = values\n",
    "    funds['Buy_hold'] = (funds['Vanguard Total Bond'] * bond_shares) + (funds['Vanguard 500 Stock'] * stock_shares)\n",
    "    funds['Active_perf'] = (funds['Active']/funds['Active'].iloc[0])\n",
    "    funds['Buy_hold_perf'] = (funds['Buy_hold']/funds['Buy_hold'].iloc[0])\n",
    "    funds['Active'] = funds['Active'].pct_change()\n",
    "    funds['Buy_hold'] = funds['Buy_hold'].pct_change()\n",
    "    funds['Stock_alloc'] = e_vals\n",
    "    funds['Bond_alloc'] = b_vals\n",
    "    funds = funds.replace(np.nan, 0)\n",
    "\n",
    "    \n",
    "    \n",
    "    return funds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_res = perfomance_bt('Sect_1_Funds.csv', clf, X, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alloc_plot(bt):\n",
    "    funds = bt\n",
    "    dates = funds.index.to_list()\n",
    "    idc = funds['indicator'].to_list()\n",
    "    recs = funds['Recession'].to_list()\n",
    "    e_vals = funds['Stock_alloc'].to_list()\n",
    "    b_vals = funds['Bond_alloc'].to_list()\n",
    "    evaluation_df = pd.DataFrame({'Dates': dates, 'Stock_alloc': e_vals, 'Bond_alloc': b_vals, 'Sig': idc, 'Recess': recs})\n",
    "    evaluation_df['Total'] = evaluation_df['Stock_alloc'] + evaluation_df['Bond_alloc']\n",
    "    evaluation_df['Stock (%)'] = evaluation_df['Stock_alloc'] /evaluation_df['Total']\n",
    "    evaluation_df['Bond (%)'] = 1-evaluation_df['Stock (%)']\n",
    "    fig_alloc = go.Figure()\n",
    "    fig_alloc.add_trace(go.Scatter(\n",
    "        x= evaluation_df['Dates'],\n",
    "        y = evaluation_df['Stock (%)'],\n",
    "        line=dict(width=0.5, color='#FFCB05'),\n",
    "        name = 'Allocation to Stocks',\n",
    "        stackgroup = 'one'))\n",
    "\n",
    "    fig_alloc.add_trace(go.Scatter(\n",
    "        x= evaluation_df['Dates'],\n",
    "        y = evaluation_df['Bond (%)'],\n",
    "        line=dict(width=0.5, color='#00274C'),\n",
    "        name = 'Allocation to Bonds',\n",
    "        stackgroup = 'one'))\n",
    "\n",
    "    fig_alloc.add_trace(go.Scatter(\n",
    "        x= evaluation_df['Dates'],\n",
    "        y = evaluation_df['Sig'],\n",
    "        line=dict(width=3, color='#9A3324'),\n",
    "        name = 'Signal'))\n",
    "\n",
    "    fig_alloc.update_yaxes(tickformat=\".2%\")\n",
    "\n",
    "    fig_alloc.update_layout(legend=dict(orientation='h',yanchor='top',xanchor='center',y=-0.05, x=0.5), paper_bgcolor='white',\n",
    "        plot_bgcolor='white' , height = 800, width = 1200, title_text='Change in Allocation Over Time', title_x=0.5)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    return fig_alloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_plot(bt):\n",
    "    funds = bt\n",
    "    funds = funds.reset_index()\n",
    "    portfolios = funds.filter(['Dates', 'Active_perf', 'Buy_hold_perf', 'indicator', 'Recession'])\n",
    "    portfolios['Active_perf'] = portfolios['Active_perf']-1\n",
    "    portfolios['Buy_hold_perf'] = portfolios['Buy_hold_perf']-1\n",
    "    fig_perf =  make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "    fig_perf.add_trace(\n",
    "        go.Scatter(\n",
    "        x = portfolios['Dates'],\n",
    "        y = portfolios['indicator'],\n",
    "        name = 'Signal',\n",
    "        line = {'color': '#9A3324'}))\n",
    "\n",
    "    fig_perf.add_trace(\n",
    "        go.Bar(\n",
    "        x = portfolios['Dates'],\n",
    "        y = portfolios['Recession'],\n",
    "        name = 'US Recession',\n",
    "    marker = {'color': '#989C97', 'line': {'width': 5}, 'opacity':0.5}))\n",
    "\n",
    "\n",
    "\n",
    "    fig_perf.add_trace(\n",
    "        go.Scatter(\n",
    "        x = portfolios['Dates'],\n",
    "        y = portfolios['Active_perf'],\n",
    "        name = 'Active Portfolio',\n",
    "        line = {'color': '#FFCB05'}),secondary_y=True)\n",
    "\n",
    "    fig_perf.add_trace(\n",
    "        go.Scatter(\n",
    "        x = portfolios['Dates'],\n",
    "        y = portfolios['Buy_hold_perf'],\n",
    "        name = '60/40 Buy & Hold Portfolio',\n",
    "        line = {'color': '#00274C'}), secondary_y=True)\n",
    "\n",
    "    fig_perf.update_yaxes(tickformat=\".2%\", title = 'Probability of Recession in 12 Months')\n",
    "    fig_perf.update_yaxes(tickformat=\".2%\", secondary_y=True, title = 'Portfolio Return')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig_perf.update_layout(legend=dict(orientation='h',yanchor='top',xanchor='center',y=-0.05, x=0.5), paper_bgcolor='white',\n",
    "        plot_bgcolor='white' , height = 800, width = 1200, title_text='Performance', title_x=0.5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    mu_a = funds['Active'].mean() * 12\n",
    "    sig_a = funds['Active'].std() * (12**0.5)\n",
    "    mu_b = funds['Buy_hold'].mean() * 12\n",
    "    sig_b = funds['Buy_hold'].std() * (12**0.5)\n",
    "\n",
    "    active_sharpe = (mu_a-0.02)/sig_a\n",
    "    bh_sharpe = (mu_b-0.02)/sig_b\n",
    "    print('Active Portfolio Sharpe: {:.2f}'.format(active_sharpe))\n",
    "    print('60/40 Buy and Hold Sharpe: {:.2f}'.format(bh_sharpe))\n",
    "\n",
    "    return fig_perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_factor_plots(indc):\n",
    "    df_polar = indc.drop(['indicator', '12_to_rec', 'Recession'], axis = 1)\n",
    "    df_polar = df_polar.reset_index()\n",
    "    for i in df_polar.columns:\n",
    "        try:\n",
    "            df_polar[i] = st.norm.cdf(df_polar[i])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    df_polar['Slope'] = 1-df_polar['Slope']\n",
    "    df_polar['PMI'] = 1-df_polar['PMI']\n",
    "    df_polar['Personal Consump'] = 1-df_polar['Personal Consump']\n",
    "    df_polar['Dates']= df_polar['Dates'].dt.strftime('%Y-%m-%d')\n",
    "    df_polar =df_polar.set_index('Dates') \n",
    "    \n",
    "    peak_dates = ['1990-02-28', '2000-09-29', '2007-05-31', '2008-04-30','2019-09-30', '2020-11-30' ]\n",
    "    colors = ['#9A3324', '#75988d', '#00B2A9', '#702082', '#CFC096', '#989C97', '#655A52']\n",
    "    pix = dict()\n",
    "    for i in  peak_dates:\n",
    "        x = list(df_polar.columns)\n",
    "        y = list(df_polar.loc[i])\n",
    "        y_text= ['{:.2%}'.format(i) for i in y]\n",
    "        fig = go.Figure(data=[go.Bar(x=x, y=y, text = y_text, textposition=\"inside\",\n",
    "                                marker_color=colors)])\n",
    "        fig.update_yaxes(tickformat=\".2%\", range=[0,1])\n",
    "        fig.update_layout(title_text = 'Factor Scores as of {}'.format(i), paper_bgcolor='white',\n",
    "        plot_bgcolor='white' , height = 500, width = 890, title_x=0.5)\n",
    "        pix[i] = fig\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_plot(bt_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alloc_plot(bt_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = get_factor_plots(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k['2019-09-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k['2007-05-31']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k['2000-09-29']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k['1990-02-28']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
