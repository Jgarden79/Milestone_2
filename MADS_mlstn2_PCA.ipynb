{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import eikon as ek\n",
    "import sys\n",
    "#import config\n",
    "ek.set_app_key(config.eikon_key)\n",
    "#import DatastreamDSWS as DSWS\n",
    "#ds = DSWS.Datastream(username = 'JGarden1@lidoadvisors.com', password= 'Welcome2')\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from arch import arch_model\n",
    "\n",
    "from tqdm import tqdm\n",
    "TOLERANCE = 1e-15\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import cufflinks as cf\n",
    "#import configparser as cp\n",
    "cf.set_config_file(offline = True)\n",
    "import cvxpy as cp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import warnings\n",
    "#warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "#from scipy.optimize import OptimizeWarning\n",
    "#warnings.simplefilter(action='ignore', category=OptimizeWarning)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import SparsePCA\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import chart_studio\n",
    "from chart_studio.plotly import plot, iplot\n",
    "import chart_studio.plotly as py\n",
    "from PIL import Image as im\n",
    "#import Lido_funcs3 as lf\n",
    "import time\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "import IPython.display\n",
    "from IPython.display import Image\n",
    "\n",
    "import chart_studio.tools as tls\n",
    "\n",
    "import plotly.io as pio\n",
    "\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "import scipy.stats as st\n",
    "from tqdm import tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#acwi = ek.get_timeseries('ACWI.O', fields = 'CLOSE', start_date = '2015-12-15', end_date = '2020-12-31',interval = 'daily')\n",
    "#acwi['ACWI'] = acwi['CLOSE']/acwi['CLOSE'].iloc[0]\n",
    "#acwi.to_csv('ACWI_DAT_sec2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Date setup\n",
    "mar = []\n",
    "jun = []\n",
    "sept = []\n",
    "dec = []\n",
    "\n",
    "for i in range(2015, 2021):\n",
    "    dt_3 = datetime.date(i, 3, 15)\n",
    "    if dt_3.isoweekday() == 6:\n",
    "        dt_3 = datetime.date(i, 3, 17)\n",
    "    elif dt_3.isoweekday() == 7:\n",
    "        dt_3 = datetime.date(i, 3, 16)\n",
    "    st_dt_3 = dt_3.strftime(\"%Y-%m-%d\")\n",
    "    mar.append(st_dt_3)\n",
    "    dt_6 = datetime.date(i, 6, 15)\n",
    "    if dt_6.isoweekday() == 6:\n",
    "        dt_6 = datetime.date(i, 6, 17)\n",
    "    elif dt_6.isoweekday() == 7:\n",
    "        dt_6 = datetime.date(i, 6, 16)\n",
    "    st_dt_6 = dt_6.strftime(\"%Y-%m-%d\")\n",
    "    jun.append(st_dt_6)\n",
    "    dt_9 = datetime.date(i, 9, 15)\n",
    "    if dt_9.isoweekday() == 6:\n",
    "        dt_9 = datetime.date(i, 9, 17)\n",
    "    elif dt_9.isoweekday() == 7:\n",
    "        dt_9 = datetime.date(i, 9, 16)\n",
    "    st_dt_9 = dt_9.strftime(\"%Y-%m-%d\")\n",
    "    sept.append(st_dt_9)\n",
    "    dt_12 = datetime.date(i, 12, 15)\n",
    "    if dt_12.isoweekday() == 6:\n",
    "        dt_12 = datetime.date(i, 12, 17)\n",
    "    elif dt_12.isoweekday() == 7:\n",
    "        dt_12 = datetime.date(i, 12, 16)\n",
    "    st_dt_12 = dt_12.strftime(\"%Y-%m-%d\")\n",
    "    dec.append(st_dt_12)\n",
    "    \n",
    "\n",
    "dates = []\n",
    "for i in range(0, len(mar)):\n",
    "    dates.append(mar[i])\n",
    "    dates.append(jun[i])\n",
    "    dates.append(sept[i])\n",
    "    dates.append(dec[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_asset_prices(asset_list, year_list):\n",
    "    '''This function takes in a list of RIC codes and years returns daily CLOSE prices for these years requires a connection to Refinitiv Eikon'''\n",
    "    \n",
    "    month = [3, 6, 9, 12] ###Call data quarterly\n",
    "    day = [31, 30, 30, 31]\n",
    "    year = year_list\n",
    "    df_prices = pd.DataFrame()\n",
    "    for y in year:\n",
    "        for m in tqdm(range(0, len(month))):\n",
    "            dt = datetime.datetime(y, month[m], day[m])\n",
    "            e_date = dt.strftime('%Y-%m-%d')\n",
    "            edt = dt - timedelta(days=95)#### 95 days ensures that the request covers a whole quarter duplicates are droped after data is receieved\n",
    "            s_date = edt.strftime('%Y-%m-%d')\n",
    "            df = ek.get_timeseries(asset_list, fields = 'CLOSE', start_date = s_date, end_date = e_date, interval = 'daily')\n",
    "            time.sleep(3) ### Sleep for three seconds between calls reduces timeouts \n",
    "            df_prices = pd.concat([df_prices, df]).drop_duplicates()\n",
    "            df_prices.sort_index()\n",
    "        \n",
    "    df_prices.to_csv('Section_2_Prices.csv')    \n",
    "    return df_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###PCA Selection\n",
    "\n",
    "def pca_func(df_px):\n",
    "    '''This function takes in a datafram of asset prices, returns a the PCA model with the fewest componants needed to explain 95% of variance + SCREE Plot'''\n",
    "    df_rets = df_px.pct_change()\n",
    "    df_rets = df_rets.replace(np.nan, 0)\n",
    "    test_pca = PCA(n_components= len(df_px.columns)).fit(df_rets)\n",
    "    vari = test_pca.explained_variance_ratio_\n",
    "    vari = [round(i,6) for i in vari]\n",
    "    cum_var = [sum(vari[0:i]) for i in range(0, len(vari))]\n",
    "    x_lst = ['PC_{}'.format(i) for i in range(1,21)]\n",
    "    fig = go.Figure(go.Bar(x = x_lst, y = vari,  marker_color='#005A9C', name = 'Variance Explained '))\n",
    "    fig.add_trace(go.Scatter(x = x_lst, y = cum_var, mode = 'markers+lines', marker_color='#EF3E42', name = 'Cumulative Variance Explained' ))\n",
    "    fig.update_yaxes(tickformat=\".2%\", range=[0,1])\n",
    "    fig.update_layout(legend=dict(orientation='h',yanchor='top',xanchor='center',y=-0.05, x=0.5), paper_bgcolor='white',\n",
    "                           plot_bgcolor='white' , height = 600, width = 1200, title_text='Variance Explained (SCREE Plot)', title_x=0.5)\n",
    "    cands = [i for i, x in enumerate(cum_var) if x>0.95]\n",
    "    n_pca = cands[0] + 1\n",
    "    pca = PCA(n_components= n_pca).fit(df_rets)\n",
    "    \n",
    "    fig.show()\n",
    "    return n_pca\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def port_vol(weights, covar):\n",
    "    weights = np.array(weights)\n",
    "    var = np.dot(np.dot(weights.T, covar), weights)\n",
    "    vol = np.sqrt(var)\n",
    "    return vol\n",
    "\n",
    "def risk_cont (weights, covar):\n",
    "    weights = np.array(weights)\n",
    "    sig = port_vol(weights, covar)\n",
    "    MCR = np.dot(covar, weights)/sig\n",
    "    RC = (MCR * weights)\n",
    "    return RC\n",
    "\n",
    "\n",
    "def _risk_budget_objective_error(weights, args):\n",
    "    covar = args[0]\n",
    "    assets_risk_budget = args[1]\n",
    "    weights = weights\n",
    "    sig = port_vol(weights, covar)\n",
    "    risk_conts = risk_cont(weights, covar)\n",
    "    risk_tgts = np.asmatrix(np.multiply(sig, assets_risk_budget))\n",
    "    error = sum(np.square(risk_conts -risk_tgts.T))[0,0]*10000\n",
    "    return error\n",
    "                \n",
    "\n",
    "def get_weights(cov, risk_tgts, w0):\n",
    "    constraints = ({'type': 'eq', 'fun': lambda x: np.sum(x) - 1.0},\n",
    "                   {'type': 'ineq', 'fun': lambda x: x})\n",
    "    \n",
    "    optimize_result = minimize(fun=_risk_budget_objective_error,\n",
    "                              x0=w0,\n",
    "                              args=[cov, risk_tgts],\n",
    "                              method='SLSQP',\n",
    "                              constraints=constraints,\n",
    "                              tol=TOLERANCE,\n",
    "                              options={ 'maxiter' : 10000,'disp': True,  'ftol': 1e-15})\n",
    "    weights = optimize_result.x\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_day(df_px, s_date, n_pca):\n",
    "    assets = df_px\n",
    "    random.seed(0)\n",
    "\n",
    "    asset_rets = assets.pct_change().dropna()\n",
    "    asset_rets = asset_rets.sort_index()\n",
    "    lb_date = s_date - timedelta(days = ((365)))\n",
    "    lb_date = datetime.datetime.strftime(lb_date, '%Y-%m-%d')\n",
    "    s_date = datetime.datetime.strftime(s_date, '%Y-%m-%d')\n",
    "    subset = asset_rets.loc[lb_date:s_date]\n",
    "    pca = PCA(n_components = 10).fit(subset)\n",
    "    comps = pca.transform(subset)\n",
    "    alpha = pca.components_\n",
    "    var_rat = pca.explained_variance_ratio_\n",
    "\n",
    "    PC_s = [comps[:,0]*100, comps[:,1]*100, comps[:,2]*100, comps[:,3]*100, comps[:,4]*100, comps[:,5]*100, comps[:,6]*100, comps[:,7]*100, comps[:,8]*100, comps[:,9]*100]\n",
    "    delta = []\n",
    "    for p in PC_s:\n",
    "        p = p.copy(order = 'C')\n",
    "        x = arch_model(p, mean ='Zero', vol = 'GARCH', p = 1, q=1, rescale = False).fit(disp = 'off')\n",
    "        y = x.forecast(horizon = 30, method = 'bootstrap')\n",
    "        z = y.variance.dropna()\n",
    "        delta.append(z['h.30'].iloc[-1])\n",
    "    delta = np.diag(delta)/10000\n",
    "    v = np.dot(np.dot(alpha.T, delta), alpha)\n",
    "    covar = pd.DataFrame(v, columns = ['XLK', 'XLV', 'XLI', 'XLU', 'XLY', 'XLF', 'XLB', 'XLE', 'XLP', 'FXI', 'EZU', 'EWJ', 'EWU', 'EWC', 'EWA'], \n",
    "                         index  = ['XLK', 'XLV', 'XLI', 'XLU', 'XLY', 'XLF', 'XLB', 'XLE', 'XLP', 'FXI', 'EZU', 'EWJ', 'EWU', 'EWC', 'EWA'])\n",
    "    \n",
    "    start = [1/len(covar) for i in range(0, len(covar))]\n",
    "    budg = [1/len(covar) for i in range(0, len(covar))]\n",
    "    \n",
    "    rpar = get_weights(covar, budg,  start)\n",
    "    \n",
    "    wghts = []\n",
    "    asset = []\n",
    "    for i in tqdm(range(0, len(rpar))):\n",
    "        x = assets.columns[i]\n",
    "        y = rpar[i]\n",
    "        wghts.append(round(y,8))\n",
    "        asset.append(x)\n",
    "    \n",
    "    rpar_vol = port_vol(rpar, covar)\n",
    "    ctr = risk_cont (rpar, covar)\n",
    "    \n",
    "    #print('Portfolio Weights:{}'.format(wghts))\n",
    "    #print()\n",
    "    #print('Volatility: {}'.format(round(rpar_vol,2)*100))\n",
    "    #print([round(c,2)*100 for c in ctr])\n",
    "    \n",
    "    res = pd.DataFrame(wghts).T\n",
    "    res.columns = asset\n",
    "    res = res.rename(columns = {'XLK': 'US TEC', 'XLV': 'US HC', 'XLI':'US IND', 'XLU': 'US UTIL', 'XLY': 'US DESC', 'XLF': 'US FIN', 'XLB': 'US MAT',\n",
    "                                'XLE': 'US ENR', 'XLP':'US STAP', 'FXI': 'CHINA', 'EZU': 'EU', 'EWJ': 'JAP', 'EWU': 'UK', 'EWC': 'CAN', 'EWA':'AUS'})\n",
    "    \n",
    "\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_bt(dates, df_px, pca):\n",
    "    bets = pd.DataFrame()\n",
    "    for d in dates[3:]:\n",
    "        d= datetime.datetime.strptime(d, '%Y-%m-%d')\n",
    "        x = run_day(df_px, d, pca)\n",
    "        bets = pd.concat([bets,x])\n",
    "    bets['Dates'] = dates[3:]\n",
    "    bets = bets.set_index('Dates')\n",
    "    performance_df = df_px.loc['2015-12-15':]\n",
    "    performance_df= performance_df.sort_index()\n",
    "    performance_df = performance_df.rename(columns = {'XLK': 'US TEC', 'XLV': 'US HC', 'XLI':'US IND', 'XLU': 'US UTIL', 'XLY': 'US DESC', 'XLF': 'US FIN', 'XLB': 'US MAT',\n",
    "                                'XLE': 'US ENR', 'XLP':'US STAP', 'FXI': 'CHINA', 'EZU': 'EU', 'EWJ': 'JAP', 'EWU': 'UK', 'EWC': 'CAN', 'EWA':'AUS'})\n",
    "    \n",
    "\n",
    "    dates = dates[3:]\n",
    "    dates_2 = dates[1:]\n",
    "\n",
    "    dates_2.append('2020-12-31')\n",
    "\n",
    "    values = []\n",
    "    date = []\n",
    "\n",
    "    cur_value = 1000000\n",
    "    classes = list(performance_df.columns)\n",
    "    \n",
    "    for i in range(0, len(dates)):\n",
    "        x = performance_df.loc[dates[i]:dates_2[i]]\n",
    "        allocation_val = bets.loc[dates[i]] * cur_value\n",
    "        shares = [k/z for k,z in zip(allocation_val,list(x.iloc[0]))]\n",
    "        for d in x.index:\n",
    "            px = x.loc[d].to_numpy()\n",
    "            shares = np.asarray(shares)\n",
    "            val = np.dot(px,shares)\n",
    "            values.append(val)\n",
    "            cur_value = val\n",
    "            date.append(d)\n",
    "            \n",
    "    ####60/40port\n",
    "    alloc_6040 =[0* 1000000, 1 * 1000000]\n",
    "    #px_stock =performance_df['LC'].iloc[0]\n",
    "    #px_bnd = performance_df['IG CORP'].iloc[0]\n",
    "    #shares = [alloc_6040[0]/px_stock, alloc_6040[1]/px_bnd]\n",
    "    #df_6040 = performance_df.filter(['LC', 'IG CORP'])\n",
    "    #val_60_40 = [np.dot(df_6040.iloc[i], shares) for i in range(0, len(df_6040))]\n",
    "            \n",
    "    \n",
    "    portfolio_df = pd.DataFrame({'Date':date, 'Value':values,})\n",
    "    portfolio_df = portfolio_df.drop_duplicates(subset = 'Date', keep = 'last')\n",
    "    \n",
    "    #portfolio_df['Bond'] = val_60_40\n",
    "    portfolio_df = portfolio_df.set_index('Date')\n",
    "    portfolio_df['Port'] = portfolio_df['Value']/portfolio_df['Value'].iloc[0]\n",
    "    #portfolio_df['Bond_Port'] = portfolio_df['Bond']/portfolio_df['Bond'].iloc[0]\n",
    "    return portfolio_df, bets\n",
    "            \n",
    "                          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alloc_over_time(bets):    \n",
    "    colors = ['#9A3324', '#75988d', '#00B2A9', '#702082', '#CFC096', '#989C97', '#655A52', '#FFCB05', '#00274C', '#EF3E42', '#552583', '#FDB927', '#000000', '#A5A508', '#2F65A7', '#CFC096']\n",
    "    cols = list(bets.columns)\n",
    "    fig_alloc = go.Figure()\n",
    "    for i in range(0, len(cols)):\n",
    "        fig_alloc.add_trace(go.Scatter(\n",
    "        x= bets.index,\n",
    "        y = bets[cols[i]],\n",
    "        line=dict(width=0.5, color=colors[i]),\n",
    "        name = 'Allocation to {}'.format(cols[i]),\n",
    "        stackgroup = 'one'))\n",
    "\n",
    "\n",
    "    fig_alloc.update_yaxes(tickformat=\".2%\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig_alloc.update_layout(legend=dict(orientation='h',yanchor='top',xanchor='center',y=-0.05, x=0.5), paper_bgcolor='white',\n",
    "                        plot_bgcolor='white' , height = 800, width = 1200, title_text='Change in Allocation Over Time', title_x=0.5)\n",
    "\n",
    "\n",
    "    return fig_alloc.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf_plot(port_df):\n",
    "    awi = pd.read_csv('ACWI_DAT_sec2.csv')\n",
    "\n",
    "    ac_perf = list(acwi['ACWI'])\n",
    "    funds = port_df\n",
    "    funds = funds.reset_index()\n",
    "    portfolios = funds.filter(['Date', 'Port', 'Bond_Port'])\n",
    "    portfolios['ACWI'] = ac_perf\n",
    "    fig_perf = go.Figure()\n",
    "\n",
    "    fig_perf.add_trace(\n",
    "        go.Scatter(\n",
    "        x = portfolios['Date'],\n",
    "        y = portfolios['Port'],\n",
    "        name = 'Risk Parity Portfolio',\n",
    "        line = {'color': '#9A3324'}))\n",
    "\n",
    "\n",
    "\n",
    "    fig_perf.add_trace(\n",
    "        go.Scatter(\n",
    "        x = portfolios['Date'],\n",
    "        y = portfolios['ACWI'],\n",
    "        name = 'All Country World Index',\n",
    "        line = {'color': '#FFCB05'}))\n",
    "\n",
    "\n",
    "\n",
    "    fig_perf.update_yaxes(tickformat=\".2%\", title = 'Portfolio Return')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig_perf.update_layout(legend=dict(orientation='h',yanchor='top',xanchor='center',y=-0.05, x=0.5), paper_bgcolor='white',\n",
    "        plot_bgcolor='white' , height = 800, width = 1200, title_text='Performance', title_x=0.5)\n",
    "    \n",
    "    daily_rp = portfolios['Port'].pct_change().dropna()\n",
    "\n",
    "    daily_acwi = portfolios['ACWI'].pct_change().dropna()\n",
    "    \n",
    "    mu_a = daily_rp.mean() *252\n",
    "\n",
    "    mu_c = daily_acwi.mean() * 252\n",
    "    \n",
    "    sig_a = daily_rp.std() * (252**0.5)\n",
    "\n",
    "    sig_c = daily_acwi.std() * (252**0.5)\n",
    "\n",
    "    active_sharpe = (mu_a)/sig_a\n",
    "\n",
    "    ac_sharpe = (mu_c)/sig_c\n",
    "    \n",
    "    \n",
    "    \n",
    "    print('RPAR Portfolio Sharpe: {:.2f}'.format(active_sharpe))\n",
    "\n",
    "    print('MSCI All Countery Index: {:.2f}'.format(ac_sharpe))\n",
    "\n",
    "\n",
    "    return fig_perf.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Plot line function to show best fit vector\n",
    "def plotline(x1,y1,x2,y2,c,l):\n",
    "    plt.scatter(x1, y1, color='black') \n",
    "    plt.plot(x2, y2, color=c, linewidth=l) \n",
    "    plt.axis('tight') \n",
    "    plt.xlabel('x') \n",
    "    plt.ylabel('y')\n",
    "    sns.despine(offset=10, trim=True)\n",
    "    \n",
    "def draw_vector(v0, v1, ax=None):\n",
    "    ax = ax or plt.gca()\n",
    "    arrowprops=dict(arrowstyle='->',\n",
    "                    linewidth=2,\n",
    "                    shrinkA=0, shrinkB=0)\n",
    "    ax.annotate('', v1, v0, arrowprops=arrowprops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def approach_1(px_close):\n",
    "    px_close = px_close.pct_change().dropna()\n",
    "    scaler = StandardScaler().fit(px_close)\n",
    "    x_scaled = scaler.transform(px_close)\n",
    "    pca = PCA(n_components=9)\n",
    "    pca.fit(x_scaled)\n",
    "    X_pca = pca.transform(x_scaled)\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    plt.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.2, s =70)\n",
    "    for length, vector in zip(pca.explained_variance_, pca.components_):\n",
    "        v = vector * 3 * np.sqrt(length)\n",
    "        draw_vector([0, 0], [9, 0])\n",
    "        draw_vector([0, 0], [0, 3])\n",
    "        plt.title('PCA Plot')\n",
    "        plt.axis('scaled')\n",
    "        plt.xlabel('PC_1 Variance explained: {:.2%}'.format(pca.explained_variance_ratio_[0]))\n",
    "        plt.ylabel('PC_2 Variance explained: {:.2%}'.format(pca.explained_variance_ratio_[1]))\n",
    "    plt.show()\n",
    "    print('PC_1 Variance explained: {:.2%}'.format(pca.explained_variance_ratio_[0]))\n",
    "    print('PC_2 Variance explained: {:.2%}'.format(pca.explained_variance_ratio_[1]))\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def MADS_MS2_A(dates):\n",
    "    asset_list = ['XLK', 'XLV', 'XLI', 'XLU', 'XLY', 'XLF', 'XLB', 'XLE', 'XLP', 'FXI', 'EZU', 'EWJ', 'EWU', 'EWC', 'EWA']\n",
    "    year_list = [2015, 2016, 2017, 2018, 2019, 2020]\n",
    "    #get_asset_prices(asset_list, year_list)\n",
    "    df_px = pd.read_csv('Section_2_Prices.csv', index_col = 'Date')\n",
    "    pca = pca_func(df_px)\n",
    "    port_df, bets = run_bt(dates, df_px, pca)\n",
    "    perf_plot(port_df)\n",
    "    alloc_over_time(bets)\n",
    "    approach_1(df_px)\n",
    "    \n",
    "    \n",
    "    return pca, port_df, bets, df_px\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca, port_df, bets, df_px = MADS_MS2_A(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approach_1(df_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
